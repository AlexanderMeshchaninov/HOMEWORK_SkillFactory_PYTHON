{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "Этот процесс также называют конструированием признаков или разработкой признаков. Все эти термины описывают процесс создания признаков, которые нужны для обучения модели.\n",
    "\n",
    "На этапе проектирования признаков специалисты по данным преследуют такие же цели, как на этапе сбора данных — сконструировать как можно больше признаков, чтобы далее отобрать из них лучшие.\n",
    "\n",
    "*Проектирование признаков* — самый творческий процесс во всём цикле жизни создания модели машинного обучения. \n",
    "\n",
    "Он включает в себя несколько этапов: \n",
    "\n",
    "* создание признаков;\n",
    "\n",
    "* преобразование признаков;\n",
    "\n",
    "* отбор признаков.\n",
    "\n",
    "Проектирование признаков необходимо для улучшения качества будущей модели: в процессе создания признаков появляются новые, возможно, более качественные, чем исходные.\n",
    "\n",
    "Новые признаки могут быть сконструированы двумя способами: \n",
    "\n",
    "* с помощью внешних источников данных;\n",
    "\n",
    "* из существующего набора данных.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример 1\n",
    "\n",
    "_В колл-центрах часто используются системы автоматического подбора номеров для дозвона (рекомендация). Если клиент во время прошлого созвона сбросил трубку, то автоматическая система должна снижать рекомендацию этого номера. Клиент вряд ли ответит после того, как бросил трубку._ \n",
    "\n",
    "В выделении этого факта нам поможет создание нового признака «сброс трубки» из информации в существующем датасете. Эта информация может быть получена из уже существующих признаков, например если время звонка составило меньше 10 секунд.\n",
    "\n",
    "## Пример 2\n",
    "\n",
    "Для определения дефолтности клиента банки делают запрос в Бюро Кредитных Историй (БКИ) с целью получения дополнительной информации по клиенту. \n",
    "\n",
    "_Такая информация о невыплаченных долгах другим организациям может быть решающим фактором в вынесении решения по кредиту. Эту информацию можно получить с использованием внешних источников данных._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новые признаки можно сконструировать из уже существующего набора данных несколькими способами: \n",
    "\n",
    "1. разбор категорий; \n",
    "\n",
    "2. разбор даты и времени;\n",
    "\n",
    "3. разбор числовых признаков;\n",
    "\n",
    "4. разбор текста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## РАЗБОР ДАТЫ И ВРЕМЕНИ\n",
    "\n",
    "Признаки, обозначающие дату и время, могут содержать много полезной информации. \n",
    "\n",
    "Например, в нашем датасете в названии вина можно увидеть год производства вина. Этот признак может оказаться важным для определения рейтинга вина. Однако, пока он заключен в названии вина, модель не сможет его использовать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## РАЗБОР ЧИСЛОВЫХ ЗНАЧЕНИЙ\n",
    "\n",
    "В наборе данных очень часто встречаются числовые величины. Это могут быть вес, рост, расстояние и так далее. Можно преобразовывать их, создавать новые признаки, которые могут оказаться лучше исходных.\n",
    "\n",
    "Например, в датасете винных обзоров числовым признаком является цена за бутылку вина. Вы можете округлить цену 35.363389$ в 35$, избавив данные от лишней информации.\n",
    "\n",
    "Помимо округления для создания новых признаков могут применяться такие популярные операции, как логарифмирование числового признака или извлечение его корня. Это подразумевает создание признаков в наиболее удобной форме для обучения модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## РАЗБОР ТЕКСТА\n",
    "\n",
    "Текстовые признаки могут содержать в себе большое количество информации. Например, если бы наша модель умела распознавать текст, то из описания вина мы бы могли понять, какими словами сомелье чаще характеризуют качественное вино. Вы можете воспользоваться методами извлечения слов из текста, чтобы получить новые признаки.\n",
    "\n",
    "В названии вина вы можете заметить указание года произведения вина. Чтобы узнать, влияет ли год на рейтинг вина, необходимо выделить год в отдельный признак.\n",
    "\n",
    "Для того, чтобы извлечь из строки число, обозначающее год, необходимо воспользоваться регулярными выражениями.\n",
    "\n",
    "_Регулярные выражения (regexp, или regex)_ — это механизм для поиска и замены текста. Это шаблоны, которые используются для поиска соответствующей части текста.\n",
    "\n",
    "Реализация такого механизма существует в pandas в работе со строками. Для того чтобы найти все числа в каждом значении серии, воспользуемся методом ``` python str.findall()```. Метод возвращает все совпадения с заданным шаблоном в серии pandas.\n",
    " \n",
    "### Разберём регулярное выражение \\d{4}:\n",
    "\n",
    "\\d — класс символов, обозначает соответствие цифрам в диапазоне цифр [0-9];\n",
    "\n",
    "{4} в шаблоне означает искать четыре вхождения символа, указанного ранее. В нашем случае это будут четырехзначные числа.\n",
    "\n",
    "Таким образом, \\d{4} означает поиск четырехзначных чисел в заданной строке.\n",
    "\n",
    "Однако при поиске числа методом ``` python data['title'].str.findall(regex) ``` результатом выполнения является список найденных цифр. Поэтому необходимо извлечь первый элемент из списка найденных методом str.get(0), где 0 — первый элемент в списке найденных чисел."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## РАЗБОР КАТЕГОРИЙ\n",
    "\n",
    "В наборе данных винных обзоров самая популярная страна-производитель вина — США. Возможно, это не случайность, и факт производства в США влияет на рейтинг вина. Выделим этот факт.\n",
    "\n",
    "Вы можете создать новый бинарный признак is_usa и присвоить ему 1 в случае, если вино произведено в США, иначе — 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# РАБОТА С ПРИЗНАКАМИ: CОЗДАНИЕ ПРИЗНАКА\n",
    "\n",
    "При создании признака часто пользуются внешними источниками даннных.\n",
    "\n",
    "_Внешние источники данных_ — дополнительные источники информации, использующиеся для обогащения датасета. \n",
    "Существует два типа внешних источников данных — \n",
    "\n",
    "- открытые; \n",
    "\n",
    "- закрытые.\n",
    "\n",
    "__Открытые источники__ доступны всем пользователям интернета. Их предоставляют такие источники, как Федеральная служба государственной статистики, Федеральная налоговая служба, Центральный банк, Википедия и так далее.\n",
    "\n",
    "__Закрытыми источниками__ являются сотовые операторы, БКИ, Госуслуги, ФССП (Федеральная служба судебных приставов) и так далее информацию из которых может запросить фирма занимающаяся анализом данных в качестве услуги.\n",
    "\n",
    "Когда данные получить необходимо, а API у источника данных нет, дата-инженеры прибегают к _парсингу_. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# РАБОТА С ФАЙЛАМИ\n",
    "\n",
    "Часто маленькие страны с небольшим количеством населения имеют узкую специализацию. Например, в производстве вина особенно успешны Франция, Италия, Испания, Новая Зеландия. Чтобы проверить, влияет ли на качество вина населённость, выясним информацию о населении страны, в котором была произведена бутылка вина.\n",
    "\n",
    "Так же на основании внешнего источника данных (дата-сет country_area) мы создадим новый признак в нашем общем дата-сете."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ВАЖНО ПОМНИТЬ, ЧТО:\n",
    "\n",
    "Внешней информации можно получить очень много. Руководствуйтесь следующими правилами при работе с внешними источниками данных:\n",
    "\n",
    "1. Старайтесь найти профильную информацию по вашей бизнес-проблеме. При предсказании рейтинга фильма информация об успехе режиссёра в других картинах будет полезнее, чем среднегодовая температура страны, в которой снят фильм.\n",
    "\n",
    "2. Если у вас много времени и ресурсов, соберите как можно больше признаков любого качества. Чем больше данных вы сгенерируете, тем выше вероятность получить качественные признаки на этапе отбора данных.\n",
    "\n",
    "3. Используйте наименее трудозатратный для вас метод поиска информации: работа с файлами, парсинг, запрос по API. Если останется время, можете попробовать другой подход.\n",
    "\n",
    "4. Не уделяйте всё время разработки поиску дополнительной информации. Вам ещё будет необходимо построить модель, вывести её в продакшн — это также требует времени.\n",
    "\n",
    "5. Помните, что цикл разработки модели цикличен: при достижении неудовлетворительных результатов вы всегда сможете вернуться на любой шаг, в том числе и на шаг проектирования признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## РАБОТА С ФОРМАТОМ \"ДАТА-ВРЕМЯ\"\n",
    "\n",
    "Большинство алгоритмов машинного обучения не умеют работать с признаками в строковом представлении, поэтому такие признаки должны быть преобразованы в формат числа.\n",
    "\n",
    "Создавая новые признаки из строковых признаков, мы также можем получить признаки в строковом представлении как в случае со временем суток. Такой признак мы по-прежнему не можем передать в модель. Но можно передать его в виде: 1 — утро, 2 — день, 3 — вечер, 4 — ночь. Этот приём часто используется дата-сайентистами для оцифровки некоторых категорий и называется __кодированием__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## КОДИРОВАНИЕ ПРИЗНАКОВ\n",
    "\n",
    "Важным этапом проектирования признаков является обработка нечисловых (категориальных) признаков. Многие модели машинного обучения не умеют работать с категориальными данными. Если мы передадим на вход модели такие признаки, она выдаст ошибку. \n",
    "\n",
    "Процесс преобразования категориальных данных в признаки, пригодные для обучения, называется кодированием признаков.\n",
    "\n",
    "Выбор подходящего метода часто может превратиться в сложную задачу, поэтому для упрощения данной задачи будем использовать схему выбора метода кодирования:\n",
    "\n",
    "\n",
    "<img src='Images/eda_3.png' width='1100' height='450'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для номинальных признаков важно количество уникальных значений признака, так как при их большом количестве могут возникать проблемы с памятью. Если у признака меньше 15 значений, следует выбирать для данных однократное кодирование (__OneHot Encoding__). \n",
    "\n",
    "Число 15 выбрано эмпирически — для вашего набора данных это число может быть 20 или 10. Это зависит от количества признаков в вашем датасете, количестве строк и многих других факторов. Если признаков немного, то вы также можете воспользоваться однократным кодированием. В других ситуациях вам стоит выбрать другой способ кодирования, например бинарный (__Binary Encoding__)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для кодирования __категориальных признаков__ мы будем использовать библиотеку category_encoders. Это удобная библиотека для кодирования категориальных переменных различными методами.\n",
    "\n",
    "Установим библиотеку:\n",
    "\n",
    "``` terminal\n",
    "    pip install category_encoders\n",
    "```\n",
    "Импортируем библиотеку category-encoders для дальнейшего использования. \n",
    "\n",
    "``` python\n",
    "    import category_encoders as ce\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Популярные способы кодирования: \n",
    "\n",
    "* порядковое кодирование (Ordinal Encoding); \n",
    "\n",
    "* однократное кодирование (OneHot Encoding); \n",
    "\n",
    "* бинарное кодирование (Binary Encoding)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ПОРЯДКОВОЕ КОДИРОВАНИЕ. ORDINAL ENCODING\n",
    "\n",
    "В порядковой кодировке признаков каждому строковому значению присваивается значение в виде целого числа, свойственного для конкретного значения строки.\n",
    "\n",
    "Результат кодирования порядкового признака size будет выглядеть так: \n",
    "\n",
    "- каждому строковому значению присваивается значение в виде целого числа.\n",
    "\n",
    "<center><img src='Images/eda_4.png' width='500' height='200'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примечание: Порядковое кодирование плохо работает для номинальных признаков. Ошибку при кодировании мы не получим, но алгоритмы машинного обучения не могут различать категории и числовые признаки, поэтому могут быть сделаны выводы о неправильном порядке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ОДНОКРАТНОЕ КОДИРОВАНИЕ. ONE-HOT ENCODING\n",
    "\n",
    "Однократное кодирование (его ещё часто называют «горячим») является автоматизированным кодированием. Для каждой новой категории создается новый бинарный признак. Значение 1 в этих признаках проставляется там, где значение исходного признака равно этой категории.\n",
    "\n",
    "<center><img src='Images/eda_5.png' width='500' height='200'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На рисунке изображено кодирование колонки color со значениями red, green, blue. Для каждого значения создаётся новый бинарный признак: red -> color_red, blue -> color_blue, green -> color_green, и проставляются значения исходного признака.\n",
    "\n",
    "Примечание: Этот способ кодирования понятен, хорошо работает как на номинальных, так и на порядковых признаках. Однако существует один минус: количество созданных признаков равно количеству уникальных значений категориального признака!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод однократного кодирования реализован в pandas в функции ```pythonpd.get_dummies()```. Для выполнения кодирования достаточно передать в функцию DataFrame и указать столбцы, для которых должно выполняться кодирование. По умолчанию кодирование выполняется для всех столбцов типа object:\n",
    "\n",
    "``` python\n",
    "    clothing_dummies = pd.get_dummies(clothing, columns=['type'])\n",
    "```\n",
    "Новые бинарные признаки также часто называются dummy-признаками или dummy-переменными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ДВОИЧНОЕ КОДИРОВАНИЕ\n",
    "\n",
    "Принцип двоичного кодирования похож на однократное кодирование, но создаёт меньше столбцов. При однократном кодировании признака с количеством уникальных категорий 100 шт. мы создадим 100 новых признаков, а при двоичном кодирования мы сгенерируем всего 7 признаков.\n",
    "\n",
    "<center><img src='Images/eda_6.png' width='500' height='200'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Сначала признак кодируется в числовое представление, как мы делали это при кодировании порядковых признаков: \n",
    "\n",
    "* hot — 1, \n",
    "\n",
    "* cold — 2, … и так далее.\n",
    "\n",
    "2. Затем каждое числовое представление, выраженное целым числом, переводится в двоичный код: \n",
    "* 1 – 001, \n",
    "\n",
    "* 2 – 010, \n",
    "\n",
    "* 3 – 011,... и так далее.\n",
    "\n",
    "3. Затем для каждого двоичного представления создаются новые признаки. В нашем случае двоичное представления уместилось в три числа, поэтому итогом стало создание трёх новых признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если рассматривать алгоритм двоичного кодирования, то его можно рассмотреть так:\n",
    "\n",
    "1. значения признака кодируются в некоторый числовой порядок;\n",
    "\n",
    "2. целые числа кодируются в двоичный код;\n",
    "\n",
    "3. цифры двоичного представления формируют новые столбцы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ПРЕОБРАЗОВАНИЕ ПРИЗНАКОВ: СТАНДАРТИЗАЦИЯ, НОРМАЛИЗАЦИЯ\n",
    "\n",
    "В машинном обучении данные часто подвергают различным преобразованиям. Самые популярные из них — это нормализация и стандартизация.\n",
    "\n",
    "Примечание: Операции нормализации и стандартизации также часто называют __шкалированием__.\n",
    "\n",
    "В наборе данных может быть заложенна проблема:\n",
    "<div style='border: 1px solid red;'>\n",
    "Данные для обучения часто представлены в различных единицах измерения, в разном масштабе. Например, в наборе данных может быть представлен признак кадастровая стоимость недвижимости, которая измеряется в миллионах рублей, и признак понижающий коэффициент, который используется для определения налога на недвижимость и измеряется в сотых долях. Или, например, в одном наборе данных встречается признак доход клиента и стаж работы на последнем месте. Стаж в редких случаях поднимается выше 10, тогда как доход измеряется тысячами.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## НОРМАЛИЗАЦИЯ\n",
    "\n",
    "__Нормализация__ — один из методов преобразования входных признаков, при котором значения признаков приводятся к неким безразмерным единицам в рамках заданного диапазона (например, [0,...,1] или [-1,...,1]) либо с каким-то заданным свойством (например, стандартным отклонением, равным 1).\n",
    "\n",
    "Существует несколько способов нормализации: MinMaxScaler, RobustScaler.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MINMAXSCALER (из библиотеки sklearn)\n",
    "\n",
    "При применении нормализации методом MinMaxScaler все значения признаков будут преобразованы в диапазон [0, 1], что означает, что минимальное и максимальное значение признака будет равно 0 и 1 соответственно.\n",
    "\n",
    "Нормализация происходит следующим способом:\n",
    "\n",
    "Из каждого значения признака х вычитается минимальное значение этого признака: $x - min$\n",
    "\n",
    "Результат вычитания делится на разность между максимумом и минимумом признака: $max - min$ \n",
    "\n",
    "$ {X}scaled - \\frac{X - {X}min}{{X}max - {X}min}$\n",
    "\n",
    "Например, температура в горном посёлке за день может меняться от 10 до 35 градусов. Текущая температура составляет 17 градусов.\n",
    "\n",
    "$ {X}scaled - \\frac{17 - 35}{35 - 10} = 0.28$\n",
    "\n",
    "Нормализованное значение 0.28 лежит в диапазоне от 0 до 1, и ближе к левой границе распределения (0), что соответствует также ненормализованному распределению (значение 17 ближе к 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс MinMaxScaler делает вышеописанную нормализацию автоматически при помощи функции преобразования fit_transform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROBUSTSCALER\n",
    "\n",
    "RobustScaler - это функция из библиотеки sklearn.preprocessing, предназначенная для нормализации числовых данных, особенно когда в наборе данных присутствуют выбросы. В отличие от стандартного масштабирования, которое использует среднее значение и стандартное отклонение, RobustScaler использует медиану и межквартильный размах (IQR) для вычисления масштаба и сдвига. Это делает его более устойчивым к выбросам, которые могут значительно исказить среднее значение и стандартное отклонение.\n",
    "\n",
    "Нормализация методом RobustScaler происходит в несколько этапов:\n",
    "\n",
    "1. из каждого значения признака вычитается медиана признака: $ x - медиана $\n",
    "\n",
    "2. полученное значение делится на межквартильный размах: $ значение $ 75 % - $ значение $ 25 $ %\n",
    "\n",
    "$ X scaler = \\frac{(X - X mediana)}{IQR} $\n",
    "\n",
    "Например, имеется числовой ряд [1, 2, 3, 4, 5]. Медиана ряда — 3. Межквартильный размах: 4 - 2 = 2. Мы хотим нормализовать число 4.\n",
    "\n",
    "$ X scaler = \\frac{(4 - 3 mediana)}{2} = 0.5 $\n",
    "\n",
    "Таким образом, значение 4 после нормализации приняло значение 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## В ЧЁМ РАЗНИЦА?\n",
    "\n",
    "Поскольку MinMaxScaler использует в своём вычислении минимальное и максимальное значения признака, то этот способ будет чувствителен к наличию выбросов в распределении.\n",
    "\n",
    "RobustScaler в вычислении использует перцентили, и поэтому не зависит даже от большого количества выбросов.\n",
    "\n",
    "Поэтому, если данные уже были очищены от выбросов, смело используйте MinMaxScaler. Этот алгоритм нормализации используется специалистами по данным чаще всего в силу его простоты и понятности, а данные на этом этапе чаще всего уже очищены. Если вы пропустили этап очистки данных и нормализуете признаки раньше, используйте нормализатор RobustScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## СТАНДАРТИЗАЦИЯ\n",
    "\n",
    "Стандартизация — ещё один метод преобразования входных признаков, при котором изменяется распределение таким образом, чтобы среднее значений равнялось 0, а стандартное отклонение — 1.\n",
    "\n",
    "$ X scaled = \\frac{(X - X mean)}{X std} $\n",
    "\n",
    "где $ X std $  — стандартное отклонение.\n",
    "\n",
    "Например, у нас есть числовой ряд [1, 2, 3, 4, 5]. Среднее ряда: 3. Стандартное отклонение — 1.4. Нормализуем число 4.\n",
    "\n",
    "$ X scaled = \\frac{(4 - 3)}{1.4} = 0.7 $\n",
    "\n",
    "Нормализованное число 4 равно 0.7.\n",
    "\n",
    "Этот процесс можно описать как центрирование данных с масштабированием. Сначала происходит вычитание среднего значения из всех данных — центрирование,  а затем деление на отклонение.\n",
    "\n",
    "## ДЛЯ ЧЕГО НЕОБХОДИМО ТАКОЕ ПРЕОБРАЗОВАНИЕ?\n",
    "\n",
    "Как и нормализация, стандартизация может быть полезна при данных с разными масштабами. Однако в отличие от нормализации стандартизация предполагает, что признак распределён нормально.\n",
    "\n",
    "Чтобы понять, как стандартизация меняет распределение, рассмотрим метод стандартизации StandardScaler в Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## НОРМАЛИЗОВАТЬ ИЛИ СТАНДАРТИЗИРОВАТЬ?\n",
    "\n",
    "Так как нормализация и стандартизация преследуют одни и те же цели, возникают вопросы:\n",
    "\n",
    "Когда признаки необходимо нормализовать, а когда стандартизировать? Какой способ нормализации выбрать?\n",
    "\n",
    "Преобразование входных переменных и выбор способа преобразования зависит от конкретной задачи и данных — заранее невозможно узнать, какое преобразования будет лучше.\n",
    "\n",
    "Однако можно составить небольшую инструкцию по преобразованию признаков:\n",
    "\n",
    "* если признак распределён __нормально__, то его необходимо __стандартизировать__;\n",
    "\n",
    "* если признак распределён __ненормально__, его необходимо __нормализовать__;\n",
    "\n",
    "* если разброс значений небольшой, то можно обойтись без преобразования данных.\n",
    "\n",
    "Что лучше? Нормализовать, а потом стандартизировать или наоборот?\n",
    "\n",
    "Комбинации преобразований также могут быть эффективны. Поэтому стоит проводить эксперименты над моделью и выбирать то сочетание преобразований, которые обеспечивают лучший результат на ваших данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ОТБОР ПРИЗНАКОВ. МУЛЬТИКОЛЛИНЕАРНОСТЬ.\n",
    "\n",
    "Ещё одним важным этапом в жизненном цикле машинного обучения и в проектировании признаков является отбор признаков.\n",
    "\n",
    "__Отбор признаков__ — процесс выбора важных признаков, наиболее влияющих на предсказание.\n",
    "\n",
    "Например, если бы мы делали отбор признаков для задачи сомелье винных обзоров, мы бы отобрали те признаки, что больше всего влияют на рейтинг вина."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ДЛЯ ЧЕГО НЕОБХОДИМО ОТБИРАТЬ ПРИЗНАКИ?\n",
    "\n",
    "Отбор признаков помогает:\n",
    "\n",
    "1. Сократить время обучения. Чем меньше данных, тем быстрее обучается модель. Например, в скоринговых моделях часто количество признаков на этапе проектирования составляет больше 500, и дата-сайентисты делают отбор признаков, чтобы исключить те признаки, которые вносят наименьший вклад. В редких случаях количество признаков в модели может быть больше 100.\n",
    "\n",
    "2. Повысить качество предсказания. Избыточные данные могут снижать точность предсказания, могут выступать в качестве «шума». Это явление называют _мультиколлинеарностью_.\n",
    "\n",
    "## КАК ПОНЯТЬ, КАКИЕ ПРИЗНАКИ БОЛЬШЕ ВСЕГО ВЛИЯЮТ НА ПРЕДСКАЗАНИЕ?\n",
    "\n",
    "Существует множество методов для отбора признаков. Однако для их использования необходимо понимать такие понятия, как: \n",
    "\n",
    "- значимость; \n",
    "\n",
    "- критерий значимости; \n",
    "\n",
    "- гипотеза.\n",
    "\n",
    "Однако есть и ещё один способ отобрать признаки для обучения — __корреляция__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Мультиколлинеарность__ — сильная корреляционная связь между признаками, отбираемыми для обучения. \n",
    "\n",
    "Сильно скоррелированные признаки сообщают для модели одну и ту же информацию. Поэтому для обучения не нужно использовать их все. Часть из них необходимо удалить из набора данных. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Процесс корреляционного анализа и удаление сильно скоррелированных признаков относят к одному из методов отбора признаков!\n",
    "\n",
    "Рассмотрим отбор признаков в Python. Для этого воспользуемся обучающим _датасетом о цветках ириса_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## КАКОЙ ПРИЗНАК УДАЛЯТЬ?\n",
    "\n",
    "Как понять, какой признак необходимо удалить из пары скоррелированных признаков?\n",
    "\n",
    "Вы можете удалить любой признак из пары. Однако вы можете оставить в наборе данных тот признак, который легче будет использовать в дальнейшем. Например, для него не понадобится округление или нормализация. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
